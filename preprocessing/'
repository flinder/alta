import spacy
import pandas as pd
import Stemmer
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

class TextProcessor(object):

    def __init__(self, language='en'):
        self.parser = spacy.load(language)
        self.stemmer = Stemmer.Stemmer(language)

    def _lemmatize(self, text):
        parsed = nlp(text)
        return ' '.join([x.lemma_ for x in parsed])

    def _stem(self, text):
        parsed = nlp(text)
        return ' '.join([self.stemmer.stemWord(x.orth_) for x in parsed])

    def vectorize(self, texts, n_gram, token_type, tfidf, stem):
        if tfidf:
            Vectorizer = TfidfVectorizer
        else:
            Vectorizer = CountVectorizer
        if stem:
            vectorizer = Vectorizer(preprocessor=self._stem, 
                                    analyzer=token_type, 
                                    ngram_range=(2,2))
        else:
            vectorizer = Vectorizer(preprocessor=self._lemmatize, 
                                    analyzer='word', 
                                    ngram_range=(2,2))

        return vectorizer.fit_transform(texts)


if __name__ == "__main__":
    '''
    Test
    '''

    text = pd.Series(["hello I'm text one. with some stuff \n in here",
                      ('text 2 here. testing the stemming. testing the '
                      'lemmatization. I dove into the pool. The dove jumped into'
                      ' the pool 999 times.')])

    text_processor = TextProcessor('en')

    output = text_processor.vectorize(text)
